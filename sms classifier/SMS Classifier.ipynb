{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4c663fa7",
   "metadata": {},
   "source": [
    "SMS Spam Classification\n",
    "\n",
    "Natural Language Processing Using Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7eb2f5c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading the libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5e85a024",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading the csv file\n",
    "messages = pd.read_csv('C://Users/thdar/Downloads/spam.csv',encoding='latin')\n",
    "\n",
    "#Specifying the names of the columns while reading csv file (tsv--tab separated values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1ef6fe61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>spam</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>ham</td>\n",
       "      <td>Will Ì_ b going to esplanade fr home?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>ham</td>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>ham</td>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>ham</td>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5572 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        v1                                                 v2 Unnamed: 2  \\\n",
       "0      ham  Go until jurong point, crazy.. Available only ...        NaN   \n",
       "1      ham                      Ok lar... Joking wif u oni...        NaN   \n",
       "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...        NaN   \n",
       "3      ham  U dun say so early hor... U c already then say...        NaN   \n",
       "4      ham  Nah I don't think he goes to usf, he lives aro...        NaN   \n",
       "...    ...                                                ...        ...   \n",
       "5567  spam  This is the 2nd time we have tried 2 contact u...        NaN   \n",
       "5568   ham              Will Ì_ b going to esplanade fr home?        NaN   \n",
       "5569   ham  Pity, * was in mood for that. So...any other s...        NaN   \n",
       "5570   ham  The guy did some bitching but I acted like i'd...        NaN   \n",
       "5571   ham                         Rofl. Its true to its name        NaN   \n",
       "\n",
       "     Unnamed: 3 Unnamed: 4  \n",
       "0           NaN        NaN  \n",
       "1           NaN        NaN  \n",
       "2           NaN        NaN  \n",
       "3           NaN        NaN  \n",
       "4           NaN        NaN  \n",
       "...         ...        ...  \n",
       "5567        NaN        NaN  \n",
       "5568        NaN        NaN  \n",
       "5569        NaN        NaN  \n",
       "5570        NaN        NaN  \n",
       "5571        NaN        NaN  \n",
       "\n",
       "[5572 rows x 5 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c067cc6",
   "metadata": {},
   "source": [
    "### Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e38998e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5572 entries, 0 to 5571\n",
      "Data columns (total 5 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   v1          5572 non-null   object\n",
      " 1   v2          5572 non-null   object\n",
      " 2   Unnamed: 2  50 non-null     object\n",
      " 3   Unnamed: 3  12 non-null     object\n",
      " 4   Unnamed: 4  6 non-null      object\n",
      "dtypes: object(5)\n",
      "memory usage: 217.8+ KB\n"
     ]
    }
   ],
   "source": [
    "#Info about the data\n",
    "messages.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c4dd77ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "v1               0\n",
       "v2               0\n",
       "Unnamed: 2    5522\n",
       "Unnamed: 3    5560\n",
       "Unnamed: 4    5566\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Finding missing values\n",
    "messages.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9a14cbac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "v1\n",
       "ham     4825\n",
       "spam     747\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Target variables counts\n",
    "messages['v1'].value_counts()\n",
    "\n",
    "#Data is imbalanced but for now we will continue with this"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae447f6f",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "\n",
    " renaming the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6a7703a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>spam</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>ham</td>\n",
       "      <td>Will Ì_ b going to esplanade fr home?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>ham</td>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>ham</td>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>ham</td>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5572 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     label                                            message Unnamed: 2  \\\n",
       "0      ham  Go until jurong point, crazy.. Available only ...        NaN   \n",
       "1      ham                      Ok lar... Joking wif u oni...        NaN   \n",
       "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...        NaN   \n",
       "3      ham  U dun say so early hor... U c already then say...        NaN   \n",
       "4      ham  Nah I don't think he goes to usf, he lives aro...        NaN   \n",
       "...    ...                                                ...        ...   \n",
       "5567  spam  This is the 2nd time we have tried 2 contact u...        NaN   \n",
       "5568   ham              Will Ì_ b going to esplanade fr home?        NaN   \n",
       "5569   ham  Pity, * was in mood for that. So...any other s...        NaN   \n",
       "5570   ham  The guy did some bitching but I acted like i'd...        NaN   \n",
       "5571   ham                         Rofl. Its true to its name        NaN   \n",
       "\n",
       "     Unnamed: 3 Unnamed: 4  \n",
       "0           NaN        NaN  \n",
       "1           NaN        NaN  \n",
       "2           NaN        NaN  \n",
       "3           NaN        NaN  \n",
       "4           NaN        NaN  \n",
       "...         ...        ...  \n",
       "5567        NaN        NaN  \n",
       "5568        NaN        NaN  \n",
       "5569        NaN        NaN  \n",
       "5570        NaN        NaN  \n",
       "5571        NaN        NaN  \n",
       "\n",
       "[5572 rows x 5 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages = messages.rename({'v1':'label', 'v2':'message'},axis='columns')\n",
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c638c062",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>spam</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>ham</td>\n",
       "      <td>Will Ì_ b going to esplanade fr home?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>ham</td>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>ham</td>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>ham</td>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5572 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     label                                            message\n",
       "0      ham  Go until jurong point, crazy.. Available only ...\n",
       "1      ham                      Ok lar... Joking wif u oni...\n",
       "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3      ham  U dun say so early hor... U c already then say...\n",
       "4      ham  Nah I don't think he goes to usf, he lives aro...\n",
       "...    ...                                                ...\n",
       "5567  spam  This is the 2nd time we have tried 2 contact u...\n",
       "5568   ham              Will Ì_ b going to esplanade fr home?\n",
       "5569   ham  Pity, * was in mood for that. So...any other s...\n",
       "5570   ham  The guy did some bitching but I acted like i'd...\n",
       "5571   ham                         Rofl. Its true to its name\n",
       "\n",
       "[5572 rows x 2 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = messages.drop(['Unnamed: 2','Unnamed: 3','Unnamed: 4'], axis = 1)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "953327f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculating length of message\n",
    "mes_len=0\n",
    "length=[]\n",
    "for i in range(len(data)):\n",
    "    length.append(len(data['message'][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1c452fcd",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[111,\n",
       " 29,\n",
       " 155,\n",
       " 49,\n",
       " 61,\n",
       " 148,\n",
       " 77,\n",
       " 160,\n",
       " 158,\n",
       " 154,\n",
       " 109,\n",
       " 136,\n",
       " 156,\n",
       " 196,\n",
       " 35,\n",
       " 149,\n",
       " 26,\n",
       " 81,\n",
       " 58,\n",
       " 156,\n",
       " 41,\n",
       " 49,\n",
       " 53,\n",
       " 88,\n",
       " 57,\n",
       " 144,\n",
       " 30,\n",
       " 134,\n",
       " 75,\n",
       " 64,\n",
       " 130,\n",
       " 189,\n",
       " 29,\n",
       " 84,\n",
       " 159,\n",
       " 123,\n",
       " 47,\n",
       " 28,\n",
       " 27,\n",
       " 155,\n",
       " 82,\n",
       " 142,\n",
       " 172,\n",
       " 19,\n",
       " 72,\n",
       " 32,\n",
       " 45,\n",
       " 31,\n",
       " 67,\n",
       " 148,\n",
       " 58,\n",
       " 124,\n",
       " 80,\n",
       " 291,\n",
       " 120,\n",
       " 76,\n",
       " 161,\n",
       " 34,\n",
       " 22,\n",
       " 40,\n",
       " 108,\n",
       " 48,\n",
       " 25,\n",
       " 56,\n",
       " 110,\n",
       " 153,\n",
       " 124,\n",
       " 161,\n",
       " 80,\n",
       " 34,\n",
       " 46,\n",
       " 29,\n",
       " 45,\n",
       " 42,\n",
       " 20,\n",
       " 43,\n",
       " 73,\n",
       " 50,\n",
       " 42,\n",
       " 76,\n",
       " 22,\n",
       " 32,\n",
       " 32,\n",
       " 36,\n",
       " 14,\n",
       " 55,\n",
       " 121,\n",
       " 144,\n",
       " 42,\n",
       " 41,\n",
       " 62,\n",
       " 195,\n",
       " 141,\n",
       " 139,\n",
       " 107,\n",
       " 125,\n",
       " 33,\n",
       " 51,\n",
       " 184,\n",
       " 57,\n",
       " 81,\n",
       " 76,\n",
       " 160,\n",
       " 183,\n",
       " 44,\n",
       " 95,\n",
       " 43,\n",
       " 82,\n",
       " 115,\n",
       " 30,\n",
       " 40,\n",
       " 31,\n",
       " 96,\n",
       " 159,\n",
       " 143,\n",
       " 156,\n",
       " 153,\n",
       " 72,\n",
       " 86,\n",
       " 144,\n",
       " 157,\n",
       " 53,\n",
       " 156,\n",
       " 52,\n",
       " 40,\n",
       " 20,\n",
       " 244,\n",
       " 22,\n",
       " 107,\n",
       " 28,\n",
       " 9,\n",
       " 39,\n",
       " 25,\n",
       " 126,\n",
       " 162,\n",
       " 38,\n",
       " 34,\n",
       " 46,\n",
       " 155,\n",
       " 86,\n",
       " 33,\n",
       " 27,\n",
       " 158,\n",
       " 42,\n",
       " 25,\n",
       " 48,\n",
       " 159,\n",
       " 84,\n",
       " 33,\n",
       " 30,\n",
       " 45,\n",
       " 59,\n",
       " 25,\n",
       " 160,\n",
       " 384,\n",
       " 28,\n",
       " 27,\n",
       " 157,\n",
       " 124,\n",
       " 146,\n",
       " 115,\n",
       " 64,\n",
       " 85,\n",
       " 152,\n",
       " 155,\n",
       " 51,\n",
       " 157,\n",
       " 74,\n",
       " 67,\n",
       " 59,\n",
       " 50,\n",
       " 94,\n",
       " 33,\n",
       " 105,\n",
       " 61,\n",
       " 65,\n",
       " 26,\n",
       " 146,\n",
       " 66,\n",
       " 126,\n",
       " 159,\n",
       " 23,\n",
       " 65,\n",
       " 24,\n",
       " 26,\n",
       " 152,\n",
       " 34,\n",
       " 149,\n",
       " 55,\n",
       " 88,\n",
       " 72,\n",
       " 185,\n",
       " 37,\n",
       " 111,\n",
       " 92,\n",
       " 28,\n",
       " 28,\n",
       " 64,\n",
       " 131,\n",
       " 40,\n",
       " 28,\n",
       " 84,\n",
       " 174,\n",
       " 24,\n",
       " 25,\n",
       " 64,\n",
       " 156,\n",
       " 28,\n",
       " 86,\n",
       " 39,\n",
       " 73,\n",
       " 26,\n",
       " 23,\n",
       " 24,\n",
       " 31,\n",
       " 58,\n",
       " 48,\n",
       " 41,\n",
       " 32,\n",
       " 159,\n",
       " 25,\n",
       " 161,\n",
       " 22,\n",
       " 119,\n",
       " 143,\n",
       " 69,\n",
       " 137,\n",
       " 30,\n",
       " 165,\n",
       " 34,\n",
       " 109,\n",
       " 37,\n",
       " 33,\n",
       " 48,\n",
       " 157,\n",
       " 50,\n",
       " 65,\n",
       " 38,\n",
       " 145,\n",
       " 145,\n",
       " 51,\n",
       " 45,\n",
       " 83,\n",
       " 155,\n",
       " 37,\n",
       " 78,\n",
       " 30,\n",
       " 31,\n",
       " 146,\n",
       " 150,\n",
       " 44,\n",
       " 179,\n",
       " 27,\n",
       " 179,\n",
       " 38,\n",
       " 97,\n",
       " 43,\n",
       " 36,\n",
       " 154,\n",
       " 74,\n",
       " 3,\n",
       " 85,\n",
       " 51,\n",
       " 121,\n",
       " 26,\n",
       " 35,\n",
       " 47,\n",
       " 159,\n",
       " 47,\n",
       " 133,\n",
       " 53,\n",
       " 147,\n",
       " 155,\n",
       " 37,\n",
       " 31,\n",
       " 8,\n",
       " 38,\n",
       " 30,\n",
       " 47,\n",
       " 56,\n",
       " 22,\n",
       " 19,\n",
       " 29,\n",
       " 7,\n",
       " 121,\n",
       " 58,\n",
       " 4,\n",
       " 148,\n",
       " 160,\n",
       " 152,\n",
       " 37,\n",
       " 55,\n",
       " 21,\n",
       " 22,\n",
       " 50,\n",
       " 159,\n",
       " 67,\n",
       " 153,\n",
       " 51,\n",
       " 67,\n",
       " 88,\n",
       " 157,\n",
       " 91,\n",
       " 24,\n",
       " 146,\n",
       " 57,\n",
       " 26,\n",
       " 71,\n",
       " 138,\n",
       " 55,\n",
       " 156,\n",
       " 134,\n",
       " 119,\n",
       " 142,\n",
       " 41,\n",
       " 26,\n",
       " 119,\n",
       " 46,\n",
       " 157,\n",
       " 23,\n",
       " 51,\n",
       " 62,\n",
       " 107,\n",
       " 157,\n",
       " 30,\n",
       " 32,\n",
       " 31,\n",
       " 79,\n",
       " 32,\n",
       " 86,\n",
       " 22,\n",
       " 76,\n",
       " 128,\n",
       " 232,\n",
       " 159,\n",
       " 45,\n",
       " 57,\n",
       " 26,\n",
       " 22,\n",
       " 41,\n",
       " 28,\n",
       " 151,\n",
       " 29,\n",
       " 34,\n",
       " 52,\n",
       " 33,\n",
       " 85,\n",
       " 31,\n",
       " 111,\n",
       " 78,\n",
       " 50,\n",
       " 63,\n",
       " 148,\n",
       " 129,\n",
       " 45,\n",
       " 202,\n",
       " 150,\n",
       " 148,\n",
       " 168,\n",
       " 85,\n",
       " 38,\n",
       " 15,\n",
       " 31,\n",
       " 88,\n",
       " 160,\n",
       " 50,\n",
       " 165,\n",
       " 129,\n",
       " 26,\n",
       " 31,\n",
       " 129,\n",
       " 34,\n",
       " 54,\n",
       " 162,\n",
       " 157,\n",
       " 23,\n",
       " 53,\n",
       " 131,\n",
       " 36,\n",
       " 143,\n",
       " 300,\n",
       " 59,\n",
       " 42,\n",
       " 41,\n",
       " 149,\n",
       " 22,\n",
       " 31,\n",
       " 30,\n",
       " 155,\n",
       " 47,\n",
       " 25,\n",
       " 80,\n",
       " 22,\n",
       " 115,\n",
       " 56,\n",
       " 102,\n",
       " 118,\n",
       " 221,\n",
       " 204,\n",
       " 114,\n",
       " 158,\n",
       " 39,\n",
       " 36,\n",
       " 48,\n",
       " 77,\n",
       " 60,\n",
       " 168,\n",
       " 51,\n",
       " 22,\n",
       " 152,\n",
       " 75,\n",
       " 30,\n",
       " 95,\n",
       " 24,\n",
       " 49,\n",
       " 35,\n",
       " 29,\n",
       " 107,\n",
       " 66,\n",
       " 159,\n",
       " 48,\n",
       " 162,\n",
       " 24,\n",
       " 137,\n",
       " 248,\n",
       " 25,\n",
       " 27,\n",
       " 37,\n",
       " 69,\n",
       " 150,\n",
       " 24,\n",
       " 80,\n",
       " 157,\n",
       " 25,\n",
       " 73,\n",
       " 89,\n",
       " 58,\n",
       " 36,\n",
       " 76,\n",
       " 47,\n",
       " 104,\n",
       " 38,\n",
       " 69,\n",
       " 22,\n",
       " 66,\n",
       " 94,\n",
       " 70,\n",
       " 73,\n",
       " 42,\n",
       " 17,\n",
       " 13,\n",
       " 45,\n",
       " 57,\n",
       " 105,\n",
       " 164,\n",
       " 47,\n",
       " 117,\n",
       " 158,\n",
       " 79,\n",
       " 142,\n",
       " 62,\n",
       " 71,\n",
       " 175,\n",
       " 29,\n",
       " 29,\n",
       " 148,\n",
       " 83,\n",
       " 37,\n",
       " 44,\n",
       " 45,\n",
       " 161,\n",
       " 50,\n",
       " 298,\n",
       " 159,\n",
       " 125,\n",
       " 51,\n",
       " 28,\n",
       " 34,\n",
       " 46,\n",
       " 81,\n",
       " 28,\n",
       " 90,\n",
       " 18,\n",
       " 54,\n",
       " 55,\n",
       " 45,\n",
       " 146,\n",
       " 40,\n",
       " 107,\n",
       " 50,\n",
       " 120,\n",
       " 160,\n",
       " 32,\n",
       " 34,\n",
       " 32,\n",
       " 16,\n",
       " 67,\n",
       " 55,\n",
       " 43,\n",
       " 23,\n",
       " 149,\n",
       " 21,\n",
       " 23,\n",
       " 40,\n",
       " 170,\n",
       " 117,\n",
       " 62,\n",
       " 166,\n",
       " 24,\n",
       " 136,\n",
       " 99,\n",
       " 45,\n",
       " 23,\n",
       " 25,\n",
       " 148,\n",
       " 26,\n",
       " 146,\n",
       " 89,\n",
       " 168,\n",
       " 117,\n",
       " 46,\n",
       " 26,\n",
       " 28,\n",
       " 32,\n",
       " 145,\n",
       " 57,\n",
       " 160,\n",
       " 42,\n",
       " 111,\n",
       " 36,\n",
       " 146,\n",
       " 50,\n",
       " 33,\n",
       " 15,\n",
       " 177,\n",
       " 160,\n",
       " 63,\n",
       " 84,\n",
       " 84,\n",
       " 57,\n",
       " 96,\n",
       " 169,\n",
       " 76,\n",
       " 47,\n",
       " 130,\n",
       " 23,\n",
       " 149,\n",
       " 32,\n",
       " 22,\n",
       " 101,\n",
       " 281,\n",
       " 54,\n",
       " 120,\n",
       " 138,\n",
       " 135,\n",
       " 66,\n",
       " 40,\n",
       " 40,\n",
       " 70,\n",
       " 160,\n",
       " 26,\n",
       " 32,\n",
       " 51,\n",
       " 160,\n",
       " 146,\n",
       " 103,\n",
       " 45,\n",
       " 142,\n",
       " 92,\n",
       " 26,\n",
       " 134,\n",
       " 37,\n",
       " 22,\n",
       " 22,\n",
       " 33,\n",
       " 69,\n",
       " 109,\n",
       " 36,\n",
       " 100,\n",
       " 140,\n",
       " 51,\n",
       " 46,\n",
       " 149,\n",
       " 63,\n",
       " 95,\n",
       " 69,\n",
       " 110,\n",
       " 55,\n",
       " 27,\n",
       " 34,\n",
       " 127,\n",
       " 142,\n",
       " 148,\n",
       " 24,\n",
       " 147,\n",
       " 24,\n",
       " 29,\n",
       " 86,\n",
       " 87,\n",
       " 38,\n",
       " 104,\n",
       " 59,\n",
       " 38,\n",
       " 38,\n",
       " 22,\n",
       " 25,\n",
       " 135,\n",
       " 87,\n",
       " 19,\n",
       " 66,\n",
       " 140,\n",
       " 156,\n",
       " 22,\n",
       " 107,\n",
       " 65,\n",
       " 149,\n",
       " 137,\n",
       " 25,\n",
       " 60,\n",
       " 103,\n",
       " 37,\n",
       " 58,\n",
       " 87,\n",
       " 58,\n",
       " 123,\n",
       " 67,\n",
       " 66,\n",
       " 102,\n",
       " 130,\n",
       " 150,\n",
       " 35,\n",
       " 8,\n",
       " 62,\n",
       " 58,\n",
       " 143,\n",
       " 20,\n",
       " 100,\n",
       " 51,\n",
       " 36,\n",
       " 53,\n",
       " 88,\n",
       " 133,\n",
       " 36,\n",
       " 37,\n",
       " 127,\n",
       " 92,\n",
       " 80,\n",
       " 136,\n",
       " 35,\n",
       " 97,\n",
       " 66,\n",
       " 119,\n",
       " 65,\n",
       " 26,\n",
       " 28,\n",
       " 45,\n",
       " 157,\n",
       " 36,\n",
       " 94,\n",
       " 59,\n",
       " 140,\n",
       " 22,\n",
       " 57,\n",
       " 43,\n",
       " 61,\n",
       " 56,\n",
       " 54,\n",
       " 37,\n",
       " 25,\n",
       " 21,\n",
       " 36,\n",
       " 42,\n",
       " 154,\n",
       " 153,\n",
       " 46,\n",
       " 34,\n",
       " 80,\n",
       " 69,\n",
       " 24,\n",
       " 108,\n",
       " 46,\n",
       " 30,\n",
       " 22,\n",
       " 158,\n",
       " 87,\n",
       " 30,\n",
       " 143,\n",
       " 169,\n",
       " 42,\n",
       " 111,\n",
       " 18,\n",
       " 109,\n",
       " 76,\n",
       " 73,\n",
       " 92,\n",
       " 36,\n",
       " 54,\n",
       " 78,\n",
       " 30,\n",
       " 40,\n",
       " 29,\n",
       " 22,\n",
       " 77,\n",
       " 109,\n",
       " 75,\n",
       " 76,\n",
       " 30,\n",
       " 49,\n",
       " 155,\n",
       " 160,\n",
       " 269,\n",
       " 195,\n",
       " 37,\n",
       " 125,\n",
       " 48,\n",
       " 39,\n",
       " 163,\n",
       " 121,\n",
       " 147,\n",
       " 162,\n",
       " 29,\n",
       " 38,\n",
       " 25,\n",
       " 40,\n",
       " 226,\n",
       " 70,\n",
       " 140,\n",
       " 47,\n",
       " 63,\n",
       " 17,\n",
       " 101,\n",
       " 41,\n",
       " 80,\n",
       " 137,\n",
       " 103,\n",
       " 29,\n",
       " 51,\n",
       " 149,\n",
       " 25,\n",
       " 149,\n",
       " 38,\n",
       " 62,\n",
       " 181,\n",
       " 34,\n",
       " 47,\n",
       " 40,\n",
       " 110,\n",
       " 132,\n",
       " 101,\n",
       " 42,\n",
       " 102,\n",
       " 65,\n",
       " 27,\n",
       " 31,\n",
       " 82,\n",
       " 23,\n",
       " 59,\n",
       " 133,\n",
       " 33,\n",
       " 95,\n",
       " 96,\n",
       " 135,\n",
       " 161,\n",
       " 151,\n",
       " 75,\n",
       " 151,\n",
       " 103,\n",
       " 22,\n",
       " 51,\n",
       " 137,\n",
       " 58,\n",
       " 89,\n",
       " 81,\n",
       " 57,\n",
       " 26,\n",
       " 32,\n",
       " 145,\n",
       " 122,\n",
       " 143,\n",
       " 23,\n",
       " 136,\n",
       " 94,\n",
       " 8,\n",
       " 99,\n",
       " 65,\n",
       " 71,\n",
       " 117,\n",
       " 129,\n",
       " 158,\n",
       " 28,\n",
       " 150,\n",
       " 31,\n",
       " 72,\n",
       " 70,\n",
       " 94,\n",
       " 48,\n",
       " 160,\n",
       " 98,\n",
       " 31,\n",
       " 43,\n",
       " 154,\n",
       " 71,\n",
       " 162,\n",
       " 143,\n",
       " 25,\n",
       " 22,\n",
       " 48,\n",
       " 33,\n",
       " 44,\n",
       " 47,\n",
       " 26,\n",
       " 112,\n",
       " 150,\n",
       " 19,\n",
       " 133,\n",
       " 48,\n",
       " 107,\n",
       " 38,\n",
       " 27,\n",
       " 129,\n",
       " 131,\n",
       " 23,\n",
       " 156,\n",
       " 161,\n",
       " 25,\n",
       " 42,\n",
       " 27,\n",
       " 22,\n",
       " 98,\n",
       " 89,\n",
       " 147,\n",
       " 130,\n",
       " 152,\n",
       " 215,\n",
       " 26,\n",
       " 66,\n",
       " 149,\n",
       " 372,\n",
       " 155,\n",
       " 162,\n",
       " 82,\n",
       " 73,\n",
       " 76,\n",
       " 153,\n",
       " 24,\n",
       " 231,\n",
       " 87,\n",
       " 72,\n",
       " 105,\n",
       " 160,\n",
       " 54,\n",
       " 58,\n",
       " 54,\n",
       " 118,\n",
       " 88,\n",
       " 144,\n",
       " 29,\n",
       " 136,\n",
       " 23,\n",
       " 39,\n",
       " 35,\n",
       " 24,\n",
       " 95,\n",
       " 73,\n",
       " 45,\n",
       " 161,\n",
       " 159,\n",
       " 149,\n",
       " 134,\n",
       " 154,\n",
       " 92,\n",
       " 102,\n",
       " 31,\n",
       " 77,\n",
       " 139,\n",
       " 158,\n",
       " 44,\n",
       " 137,\n",
       " 132,\n",
       " 143,\n",
       " 127,\n",
       " 276,\n",
       " 78,\n",
       " 27,\n",
       " 79,\n",
       " 24,\n",
       " 52,\n",
       " 68,\n",
       " 24,\n",
       " 44,\n",
       " 24,\n",
       " 55,\n",
       " 62,\n",
       " 104,\n",
       " 87,\n",
       " 150,\n",
       " 49,\n",
       " 154,\n",
       " 56,\n",
       " 125,\n",
       " 126,\n",
       " 43,\n",
       " 77,\n",
       " 49,\n",
       " 84,\n",
       " 49,\n",
       " 162,\n",
       " 79,\n",
       " 31,\n",
       " 155,\n",
       " 146,\n",
       " 23,\n",
       " 160,\n",
       " 62,\n",
       " 39,\n",
       " 67,\n",
       " 73,\n",
       " 148,\n",
       " 88,\n",
       " 37,\n",
       " 23,\n",
       " 56,\n",
       " 53,\n",
       " 73,\n",
       " 80,\n",
       " 44,\n",
       " 92,\n",
       " 35,\n",
       " 23,\n",
       " 140,\n",
       " 106,\n",
       " 103,\n",
       " 34,\n",
       " 77,\n",
       " 159,\n",
       " 26,\n",
       " 47,\n",
       " 24,\n",
       " 149,\n",
       " 133,\n",
       " 126,\n",
       " 78,\n",
       " 132,\n",
       " 116,\n",
       " 221,\n",
       " 59,\n",
       " 137,\n",
       " 143,\n",
       " 24,\n",
       " 38,\n",
       " 42,\n",
       " 24,\n",
       " 159,\n",
       " 47,\n",
       " 41,\n",
       " 122,\n",
       " 126,\n",
       " 26,\n",
       " 114,\n",
       " 7,\n",
       " 34,\n",
       " 157,\n",
       " 92,\n",
       " 90,\n",
       " 22,\n",
       " 85,\n",
       " 63,\n",
       " 220,\n",
       " 41,\n",
       " 60,\n",
       " 88,\n",
       " 31,\n",
       " 37,\n",
       " 28,\n",
       " 24,\n",
       " 118,\n",
       " 22,\n",
       " 210,\n",
       " 50,\n",
       " 49,\n",
       " 87,\n",
       " 61,\n",
       " 141,\n",
       " 54,\n",
       " 28,\n",
       " 49,\n",
       " 53,\n",
       " 145,\n",
       " 162,\n",
       " 53,\n",
       " 12,\n",
       " 142,\n",
       " 73,\n",
       " 129,\n",
       " 33,\n",
       " 47,\n",
       " 72,\n",
       " 148,\n",
       " 107,\n",
       " 41,\n",
       " ...]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c412f1ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding Length column to the dataframe\n",
    "data['Length']=length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8bac8bc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "      <th>Length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                            message  Length\n",
       "0   ham  Go until jurong point, crazy.. Available only ...     111\n",
       "1   ham                      Ok lar... Joking wif u oni...      29\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...     155\n",
       "3   ham  U dun say so early hor... U c already then say...      49\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...      61"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "74512228",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "count=0\n",
    "punct=[]\n",
    "for i in range(len(data)):\n",
    "    for j in messages['message'][i]:\n",
    "        if j in string.punctuation:\n",
    "            count+=1\n",
    "    #print(count)\n",
    "    punct.append(count)\n",
    "    count=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "683b09b5",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[9,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 2,\n",
       " 8,\n",
       " 2,\n",
       " 6,\n",
       " 6,\n",
       " 2,\n",
       " 6,\n",
       " 8,\n",
       " 8,\n",
       " 4,\n",
       " 2,\n",
       " 11,\n",
       " 6,\n",
       " 5,\n",
       " 1,\n",
       " 8,\n",
       " 1,\n",
       " 0,\n",
       " 7,\n",
       " 3,\n",
       " 2,\n",
       " 7,\n",
       " 1,\n",
       " 6,\n",
       " 7,\n",
       " 4,\n",
       " 4,\n",
       " 7,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 7,\n",
       " 3,\n",
       " 0,\n",
       " 6,\n",
       " 7,\n",
       " 3,\n",
       " 15,\n",
       " 5,\n",
       " 1,\n",
       " 10,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 7,\n",
       " 2,\n",
       " 11,\n",
       " 1,\n",
       " 16,\n",
       " 5,\n",
       " 6,\n",
       " 12,\n",
       " 3,\n",
       " 0,\n",
       " 3,\n",
       " 5,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 10,\n",
       " 10,\n",
       " 7,\n",
       " 1,\n",
       " 9,\n",
       " 1,\n",
       " 1,\n",
       " 6,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 5,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 5,\n",
       " 4,\n",
       " 4,\n",
       " 1,\n",
       " 5,\n",
       " 3,\n",
       " 5,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 6,\n",
       " 3,\n",
       " 1,\n",
       " 9,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 6,\n",
       " 8,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 6,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 4,\n",
       " 6,\n",
       " 15,\n",
       " 13,\n",
       " 7,\n",
       " 4,\n",
       " 6,\n",
       " 3,\n",
       " 6,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 9,\n",
       " 1,\n",
       " 4,\n",
       " 5,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 5,\n",
       " 8,\n",
       " 4,\n",
       " 1,\n",
       " 1,\n",
       " 4,\n",
       " 13,\n",
       " 2,\n",
       " 2,\n",
       " 11,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 7,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 6,\n",
       " 6,\n",
       " 16,\n",
       " 1,\n",
       " 4,\n",
       " 8,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 5,\n",
       " 5,\n",
       " 13,\n",
       " 6,\n",
       " 1,\n",
       " 5,\n",
       " 3,\n",
       " 2,\n",
       " 5,\n",
       " 2,\n",
       " 12,\n",
       " 1,\n",
       " 6,\n",
       " 7,\n",
       " 1,\n",
       " 1,\n",
       " 14,\n",
       " 1,\n",
       " 5,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 7,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 5,\n",
       " 5,\n",
       " 8,\n",
       " 4,\n",
       " 2,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 5,\n",
       " 8,\n",
       " 5,\n",
       " 0,\n",
       " 16,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 13,\n",
       " 1,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 0,\n",
       " 7,\n",
       " 7,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 5,\n",
       " 2,\n",
       " 5,\n",
       " 2,\n",
       " 6,\n",
       " 11,\n",
       " 2,\n",
       " 6,\n",
       " 1,\n",
       " 12,\n",
       " 0,\n",
       " 7,\n",
       " 0,\n",
       " 2,\n",
       " 4,\n",
       " 8,\n",
       " 6,\n",
       " 0,\n",
       " 2,\n",
       " 14,\n",
       " 3,\n",
       " 1,\n",
       " 0,\n",
       " 5,\n",
       " 9,\n",
       " 2,\n",
       " 3,\n",
       " 0,\n",
       " 1,\n",
       " 5,\n",
       " 3,\n",
       " 0,\n",
       " 11,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 5,\n",
       " 0,\n",
       " 4,\n",
       " 3,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 7,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 7,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 14,\n",
       " 7,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 8,\n",
       " 1,\n",
       " 11,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 5,\n",
       " 2,\n",
       " 0,\n",
       " 15,\n",
       " 9,\n",
       " 1,\n",
       " 3,\n",
       " 6,\n",
       " 2,\n",
       " 3,\n",
       " 10,\n",
       " 3,\n",
       " 6,\n",
       " 2,\n",
       " 4,\n",
       " 14,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 6,\n",
       " 2,\n",
       " 6,\n",
       " 2,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 2,\n",
       " 3,\n",
       " 5,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 7,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 7,\n",
       " 4,\n",
       " 1,\n",
       " 8,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 7,\n",
       " 1,\n",
       " 7,\n",
       " 7,\n",
       " 3,\n",
       " 9,\n",
       " 10,\n",
       " 5,\n",
       " 7,\n",
       " 2,\n",
       " 1,\n",
       " 5,\n",
       " 8,\n",
       " 2,\n",
       " 11,\n",
       " 6,\n",
       " 2,\n",
       " 2,\n",
       " 9,\n",
       " 2,\n",
       " 8,\n",
       " 1,\n",
       " 3,\n",
       " 0,\n",
       " 6,\n",
       " 3,\n",
       " 0,\n",
       " 5,\n",
       " 14,\n",
       " 1,\n",
       " 5,\n",
       " 4,\n",
       " 4,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 6,\n",
       " 11,\n",
       " 11,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 6,\n",
       " 1,\n",
       " 6,\n",
       " 3,\n",
       " 0,\n",
       " 9,\n",
       " 0,\n",
       " 0,\n",
       " 12,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 5,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 30,\n",
       " 3,\n",
       " 4,\n",
       " 1,\n",
       " 5,\n",
       " 17,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 9,\n",
       " 17,\n",
       " 2,\n",
       " 0,\n",
       " 3,\n",
       " 2,\n",
       " 8,\n",
       " 4,\n",
       " 9,\n",
       " 2,\n",
       " 2,\n",
       " 6,\n",
       " 6,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 1,\n",
       " 0,\n",
       " 6,\n",
       " 2,\n",
       " 9,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 6,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 8,\n",
       " 2,\n",
       " 0,\n",
       " 11,\n",
       " 2,\n",
       " 1,\n",
       " 4,\n",
       " 2,\n",
       " 5,\n",
       " 2,\n",
       " 18,\n",
       " 7,\n",
       " 10,\n",
       " 1,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 0,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 12,\n",
       " 2,\n",
       " 6,\n",
       " 2,\n",
       " 4,\n",
       " 6,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 4,\n",
       " 2,\n",
       " 1,\n",
       " 5,\n",
       " 7,\n",
       " 5,\n",
       " 2,\n",
       " 12,\n",
       " 2,\n",
       " 12,\n",
       " 2,\n",
       " 8,\n",
       " 2,\n",
       " 4,\n",
       " 7,\n",
       " 3,\n",
       " 7,\n",
       " 5,\n",
       " 5,\n",
       " 3,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 10,\n",
       " 4,\n",
       " 10,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 8,\n",
       " 7,\n",
       " 7,\n",
       " 4,\n",
       " 6,\n",
       " 5,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 6,\n",
       " 15,\n",
       " 4,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 7,\n",
       " 4,\n",
       " 9,\n",
       " 3,\n",
       " 2,\n",
       " 4,\n",
       " 1,\n",
       " 2,\n",
       " 4,\n",
       " 1,\n",
       " 4,\n",
       " 19,\n",
       " 5,\n",
       " 4,\n",
       " 3,\n",
       " 6,\n",
       " 16,\n",
       " 2,\n",
       " 2,\n",
       " 7,\n",
       " 3,\n",
       " 1,\n",
       " 9,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 6,\n",
       " 5,\n",
       " 2,\n",
       " 2,\n",
       " 5,\n",
       " 4,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 4,\n",
       " 1,\n",
       " 12,\n",
       " 4,\n",
       " 0,\n",
       " 2,\n",
       " 11,\n",
       " 7,\n",
       " 9,\n",
       " 1,\n",
       " 9,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 8,\n",
       " 4,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 0,\n",
       " 8,\n",
       " 0,\n",
       " 3,\n",
       " 4,\n",
       " 2,\n",
       " 9,\n",
       " 0,\n",
       " 1,\n",
       " 3,\n",
       " 8,\n",
       " 4,\n",
       " 2,\n",
       " 7,\n",
       " 3,\n",
       " 5,\n",
       " 5,\n",
       " 1,\n",
       " 4,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 13,\n",
       " 3,\n",
       " 3,\n",
       " 6,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 7,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 8,\n",
       " 2,\n",
       " 9,\n",
       " 2,\n",
       " 11,\n",
       " 4,\n",
       " 6,\n",
       " 3,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 4,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 11,\n",
       " 2,\n",
       " 7,\n",
       " 9,\n",
       " 3,\n",
       " 4,\n",
       " 1,\n",
       " 6,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 7,\n",
       " 8,\n",
       " 3,\n",
       " 4,\n",
       " 8,\n",
       " 1,\n",
       " 6,\n",
       " 4,\n",
       " 2,\n",
       " 1,\n",
       " 9,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 6,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 8,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 4,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 6,\n",
       " 7,\n",
       " 2,\n",
       " 0,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 12,\n",
       " 0,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 7,\n",
       " 9,\n",
       " 2,\n",
       " 4,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 0,\n",
       " 10,\n",
       " 5,\n",
       " 13,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 4,\n",
       " 3,\n",
       " 2,\n",
       " 4,\n",
       " 3,\n",
       " 0,\n",
       " 2,\n",
       " 9,\n",
       " 1,\n",
       " 7,\n",
       " 2,\n",
       " 4,\n",
       " 8,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 5,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 6,\n",
       " 1,\n",
       " 2,\n",
       " 5,\n",
       " 0,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 5,\n",
       " 12,\n",
       " 6,\n",
       " 5,\n",
       " 10,\n",
       " 2,\n",
       " 1,\n",
       " 6,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 6,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 6,\n",
       " 3,\n",
       " 0,\n",
       " 12,\n",
       " 11,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 5,\n",
       " 6,\n",
       " 0,\n",
       " 4,\n",
       " 3,\n",
       " 11,\n",
       " 3,\n",
       " 6,\n",
       " 2,\n",
       " 8,\n",
       " 4,\n",
       " 1,\n",
       " 9,\n",
       " 9,\n",
       " 7,\n",
       " 7,\n",
       " 4,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 4,\n",
       " 10,\n",
       " 4,\n",
       " 3,\n",
       " 1,\n",
       " 5,\n",
       " 6,\n",
       " 4,\n",
       " 0,\n",
       " 0,\n",
       " 10,\n",
       " 9,\n",
       " 0,\n",
       " 10,\n",
       " 5,\n",
       " 1,\n",
       " 10,\n",
       " 2,\n",
       " 2,\n",
       " 6,\n",
       " 3,\n",
       " 6,\n",
       " 1,\n",
       " 13,\n",
       " 8,\n",
       " 2,\n",
       " 14,\n",
       " 0,\n",
       " 13,\n",
       " 0,\n",
       " 7,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 6,\n",
       " 4,\n",
       " 10,\n",
       " 3,\n",
       " 8,\n",
       " 4,\n",
       " 10,\n",
       " 2,\n",
       " 5,\n",
       " 1,\n",
       " 7,\n",
       " 5,\n",
       " 4,\n",
       " 1,\n",
       " 7,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 4,\n",
       " 1,\n",
       " 0,\n",
       " 4,\n",
       " 2,\n",
       " 9,\n",
       " 4,\n",
       " 4,\n",
       " 2,\n",
       " 8,\n",
       " 1,\n",
       " 3,\n",
       " 19,\n",
       " 7,\n",
       " 1,\n",
       " 5,\n",
       " 3,\n",
       " 5,\n",
       " 9,\n",
       " 9,\n",
       " 5,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 5,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 4,\n",
       " 7,\n",
       " 5,\n",
       " 7,\n",
       " 10,\n",
       " 1,\n",
       " 7,\n",
       " 4,\n",
       " 6,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 6,\n",
       " 2,\n",
       " 0,\n",
       " 11,\n",
       " 4,\n",
       " 1,\n",
       " 11,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 11,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 5,\n",
       " 4,\n",
       " 8,\n",
       " 5,\n",
       " 4,\n",
       " 1,\n",
       " 6,\n",
       " 8,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 5,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 6,\n",
       " 4,\n",
       " 6,\n",
       " 2,\n",
       " 5,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 8,\n",
       " 4,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 6,\n",
       " 11,\n",
       " 1,\n",
       " 0,\n",
       " 13,\n",
       " 7,\n",
       " 0,\n",
       " 4,\n",
       " 1,\n",
       " 2,\n",
       " 5,\n",
       " 8,\n",
       " 3,\n",
       " 0,\n",
       " 6,\n",
       " 3,\n",
       " 9,\n",
       " 1,\n",
       " 3,\n",
       " 4,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 8,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 7,\n",
       " 1,\n",
       " 0,\n",
       " 6,\n",
       " 9,\n",
       " 13,\n",
       " 13,\n",
       " 3,\n",
       " 0,\n",
       " 4,\n",
       " 10,\n",
       " 11,\n",
       " 4,\n",
       " 7,\n",
       " 3,\n",
       " 5,\n",
       " 5,\n",
       " 1,\n",
       " ...]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "punct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "49324588",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding punctuation length column to dataframe\n",
    "data[\"Punctuation\"]=punct"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f239e5ea",
   "metadata": {},
   "source": [
    "## Text Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "405212f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Regex\n",
    "import re\n",
    "\n",
    "#Stopwords\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "#Lemmatization\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "#Creating object for Lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "029f787b",
   "metadata": {},
   "outputs": [
    {
     "ename": "LookupError",
     "evalue": "\n**********************************************************************\n  Resource \u001b[93mstopwords\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('stopwords')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/stopwords\u001b[0m\n\n  Searched in:\n    - 'C:\\\\Users\\\\thdar/nltk_data'\n    - 'C:\\\\Users\\\\thdar\\\\anaconda3\\\\nltk_data'\n    - 'C:\\\\Users\\\\thdar\\\\anaconda3\\\\share\\\\nltk_data'\n    - 'C:\\\\Users\\\\thdar\\\\anaconda3\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\thdar\\\\AppData\\\\Roaming\\\\nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n**********************************************************************\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\nltk\\corpus\\util.py:84\u001b[0m, in \u001b[0;36mLazyCorpusLoader.__load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 84\u001b[0m     root \u001b[38;5;241m=\u001b[39m nltk\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mfind(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msubdir\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mzip_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     85\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\nltk\\data.py:583\u001b[0m, in \u001b[0;36mfind\u001b[1;34m(resource_name, paths)\u001b[0m\n\u001b[0;32m    582\u001b[0m resource_not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mmsg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 583\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m(resource_not_found)\n",
      "\u001b[1;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mstopwords\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('stopwords')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/stopwords.zip/stopwords/\u001b[0m\n\n  Searched in:\n    - 'C:\\\\Users\\\\thdar/nltk_data'\n    - 'C:\\\\Users\\\\thdar\\\\anaconda3\\\\nltk_data'\n    - 'C:\\\\Users\\\\thdar\\\\anaconda3\\\\share\\\\nltk_data'\n    - 'C:\\\\Users\\\\thdar\\\\anaconda3\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\thdar\\\\AppData\\\\Roaming\\\\nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n**********************************************************************\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 12\u001b[0m\n\u001b[0;32m      9\u001b[0m words \u001b[38;5;241m=\u001b[39m words\u001b[38;5;241m.\u001b[39msplit()\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m#Lemmatizing the word and removing the stopwords\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m words \u001b[38;5;241m=\u001b[39m [lemmatizer\u001b[38;5;241m.\u001b[39mlemmatize(word) \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m words \u001b[38;5;28;01mif\u001b[39;00m word \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mset\u001b[39m(stopwords\u001b[38;5;241m.\u001b[39mwords(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124menglish\u001b[39m\u001b[38;5;124m'\u001b[39m))]\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m#Again join words to form sentences\u001b[39;00m\n\u001b[0;32m     15\u001b[0m words \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(words)\n",
      "Cell \u001b[1;32mIn[24], line 12\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      9\u001b[0m words \u001b[38;5;241m=\u001b[39m words\u001b[38;5;241m.\u001b[39msplit()\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m#Lemmatizing the word and removing the stopwords\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m words \u001b[38;5;241m=\u001b[39m [lemmatizer\u001b[38;5;241m.\u001b[39mlemmatize(word) \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m words \u001b[38;5;28;01mif\u001b[39;00m word \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mset\u001b[39m(stopwords\u001b[38;5;241m.\u001b[39mwords(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124menglish\u001b[39m\u001b[38;5;124m'\u001b[39m))]\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m#Again join words to form sentences\u001b[39;00m\n\u001b[0;32m     15\u001b[0m words \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(words)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\nltk\\corpus\\util.py:121\u001b[0m, in \u001b[0;36mLazyCorpusLoader.__getattr__\u001b[1;34m(self, attr)\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attr \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__bases__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    119\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLazyCorpusLoader object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__bases__\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 121\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__load()\n\u001b[0;32m    122\u001b[0m \u001b[38;5;66;03m# This looks circular, but its not, since __load() changes our\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;66;03m# __class__ to something new:\u001b[39;00m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, attr)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\nltk\\corpus\\util.py:86\u001b[0m, in \u001b[0;36mLazyCorpusLoader.__load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     84\u001b[0m             root \u001b[38;5;241m=\u001b[39m nltk\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mfind(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msubdir\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mzip_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     85\u001b[0m         \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m:\n\u001b[1;32m---> 86\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m     88\u001b[0m \u001b[38;5;66;03m# Load the corpus.\u001b[39;00m\n\u001b[0;32m     89\u001b[0m corpus \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__reader_cls(root, \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__kwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\nltk\\corpus\\util.py:81\u001b[0m, in \u001b[0;36mLazyCorpusLoader.__load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     79\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     80\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 81\u001b[0m         root \u001b[38;5;241m=\u001b[39m nltk\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mfind(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msubdir\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     82\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     83\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\nltk\\data.py:583\u001b[0m, in \u001b[0;36mfind\u001b[1;34m(resource_name, paths)\u001b[0m\n\u001b[0;32m    581\u001b[0m sep \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m*\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m70\u001b[39m\n\u001b[0;32m    582\u001b[0m resource_not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mmsg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 583\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m(resource_not_found)\n",
      "\u001b[1;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mstopwords\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('stopwords')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/stopwords\u001b[0m\n\n  Searched in:\n    - 'C:\\\\Users\\\\thdar/nltk_data'\n    - 'C:\\\\Users\\\\thdar\\\\anaconda3\\\\nltk_data'\n    - 'C:\\\\Users\\\\thdar\\\\anaconda3\\\\share\\\\nltk_data'\n    - 'C:\\\\Users\\\\thdar\\\\anaconda3\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\thdar\\\\AppData\\\\Roaming\\\\nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n**********************************************************************\n"
     ]
    }
   ],
   "source": [
    "#Removal of extra characters and stop words and lemmatization\n",
    "corpus = []\n",
    "\n",
    "#Skipping the 0th index (it's of Label)\n",
    "for i in range(0,len(data)):\n",
    "    words = re.sub('[^a-zA-Z]',' ',data['message'][i])\n",
    "    words = words.lower()\n",
    "    #Splits into list of words \n",
    "    words = words.split()\n",
    "    \n",
    "    #Lemmatizing the word and removing the stopwords\n",
    "    words = [lemmatizer.lemmatize(word) for word in words if word not in set(stopwords.words('english'))]\n",
    "    \n",
    "    #Again join words to form sentences\n",
    "    words = ' '.join(words)\n",
    "    \n",
    "    corpus.append(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc81886b",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26683afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replacing Original Message with the Transformed Messages\n",
    "data['message'] = corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f6fb6661",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m data\u001b[38;5;241m.\u001b[39mhead()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90c45f39",
   "metadata": {},
   "source": [
    "# Analyzing the difference between Spam and Ham messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7264c891",
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_messages = messages[messages['Label'] == 'spam']\n",
    "ham_messages = messages[messages['Label'] == 'ham']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8564efd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_messages.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97108699",
   "metadata": {},
   "outputs": [],
   "source": [
    "ham_messages.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a92e19d",
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_messages['Length'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d82e01e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ham_messages['Length'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f7e2b9e",
   "metadata": {},
   "source": [
    "We can see that Spam messages have more average words than Ham messages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b6f2c04",
   "metadata": {},
   "source": [
    "# Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6abb27ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data['message']\n",
    "y = data['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a32599ea",
   "metadata": {},
   "source": [
    "#### Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8855fa73",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train , X_test , y_train , y_test = train_test_split(X , y, test_size = 0.33, random_state = 42)\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b53c5790",
   "metadata": {},
   "source": [
    "### Demonstration of Count Vectorizer\n",
    "(Bag of Words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d036f012",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vect=CountVectorizer()\n",
    "X_train_count_vect=count_vect.fit_transform(X_train).toarray()\n",
    "X_train_count_vect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace5974f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3733 are the sentences and 5772 are the words in total sentences\n",
    "X_train_count_vect.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e60c77bc",
   "metadata": {},
   "source": [
    "#### Note:-\n",
    "There might be that, some words in 5772 words are not frequently present and are just appearing 1-2 times, we can reduce them using cv = CountVectorizer(max_features = 4000) (an approach)\n",
    "\n",
    "This will only take 4000 words leading to coming of most frequent words\n",
    "\n",
    "We can change the max_features, according to what we want"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03c22c5c",
   "metadata": {},
   "source": [
    "## Demonstration of TF-IDF Vectorizer\n",
    "(Term Frequency - Inverse Document Frequency)\n",
    "\n",
    "CountVectorizer(Bag of Words) + TFIDF Transformer, Scikit-Learn has provided with a method of TFIDF vectorizer (combining two steps into one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e30342c0",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'count_vect' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeature_extraction\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtext\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TfidfVectorizer\n\u001b[0;32m      2\u001b[0m tfidf\u001b[38;5;241m=\u001b[39mTfidfVectorizer()\n\u001b[1;32m----> 3\u001b[0m X_train_tfidf_vect\u001b[38;5;241m=\u001b[39mcount_vect\u001b[38;5;241m.\u001b[39mfit_transform(X_train)\u001b[38;5;241m.\u001b[39mtoarray()\n\u001b[0;32m      4\u001b[0m X_train_tfidf_vect\n",
      "\u001b[1;31mNameError\u001b[0m: name 'count_vect' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf=TfidfVectorizer()\n",
    "X_train_tfidf_vect=count_vect.fit_transform(X_train).toarray()\n",
    "X_train_tfidf_vect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8505321",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tfidf_vect.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3e3ab49",
   "metadata": {},
   "source": [
    "## Pipelining\n",
    "\n",
    "We are doing pipelining as we need to perform the same procedures for the test data to get predictions, that may be tiresome.\n",
    "\n",
    "However what convenient about this pipeline object is that it actually can perform all these steps for you in a single cell, that means you can directly provide the data and it will be both vectorized and run the classifier on it in a single step.\n",
    "\n",
    "Pipeline takes list of tuple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0a5df9fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f315cff7",
   "metadata": {},
   "source": [
    "## Naive Bayer Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c56d603",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "#each tuple takes the name you decide , next you call what you want to occur\n",
    "text_mnb=Pipeline([('tfidf',TfidfVectorizer()),('mnb',MultinomialNB())])\n",
    "#Now u can directly pass the X_train dataset.\n",
    "text_mnb.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd33766c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#It will take the X_test and do all the steps, vectorize it and predict it\n",
    "y_preds_mnb=text_mnb.predict(X_test)\n",
    "#Predictions of the test data\n",
    "y_preds_mnb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0865b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training score\n",
    "text_mnb.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f9aa17a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing score\n",
    "text_mnb.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09d44acb",
   "metadata": {},
   "source": [
    "Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38cd487e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(y_test,y_preds_mnb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fcce472",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test,y_preds_mnb))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9968b3f5",
   "metadata": {},
   "source": [
    "## SVM Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d67b0df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "#each tuple takes the name you decide , next you call what you want to occur\n",
    "text_svm=Pipeline([('tfidf',TfidfVectorizer()),('svm',LinearSVC())])\n",
    "#Now u can directly pass the X_train dataset.\n",
    "text_svm.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b96d5a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "#It will take the X_test and do all the steps, vectorize it and predict it\n",
    "y_preds_svm=text_svm.predict(X_test)\n",
    "#Predictions of the test data\n",
    "y_preds_svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c08eeee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training score\n",
    "text_svm.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a96132a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing score\n",
    "text_svm.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c03bf43d",
   "metadata": {},
   "source": [
    "#### Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "71fa024a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m confusion_matrix\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28mprint\u001b[39m(confusion_matrix(y_test,y_preds_svm))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'y_test' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(y_test,y_preds_svm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b28348f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test,y_preds_svm))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b926a30e",
   "metadata": {},
   "source": [
    "## Prediciting on New SMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e03ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'Congratulations, you have won a lottery of $5000. To Won Text on,555500 '\n",
    "def refined_text(text):\n",
    "    #Removal of extra characters and stop words\n",
    "    words = re.sub('[^a-zA-Z]',' ',text)\n",
    "    words = words.lower()\n",
    "    #Splits into list of words \n",
    "    words = words.split()\n",
    "\n",
    "    #Lemmatizing the word and removing the stopwords\n",
    "    words = [lemmatizer.lemmatize(word) for word in words if word not in set(stopwords.words('english'))]\n",
    "\n",
    "    #Again join words to form sentences\n",
    "    words = ' '.join(words)\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1651abdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "refined_word = refined_text(text)\n",
    "refined_word = [refined_word]\n",
    "refined_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a8dab19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directly predicting the single message to the model\n",
    "text_mnb.predict(refined_word)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
